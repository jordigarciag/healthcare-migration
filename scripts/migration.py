# ============================================================================
# SCRIPT DE MIGRATION : CSV ‚Üí MongoDB
# ============================================================================
# Ce script migre des donn√©es m√©dicales depuis un fichier CSV vers MongoDB.
# Auteur : DataSoluTech
# Date : Janvier 2026
# ============================================================================


# ============================================================================
# IMPORTS : Biblioth√®ques n√©cessaires
# ============================================================================

import pandas as pd
# pandas (pd) : Biblioth√®que pour manipuler des donn√©es tabulaires (CSV, Excel, etc.)
# C'est l'outil principal pour lire et transformer des fichiers CSV

from pymongo import MongoClient, ASCENDING
# pymongo : Biblioth√®que officielle pour connecter Python √† MongoDB
# - MongoClient : Classe pour cr√©er une connexion √† MongoDB
# - ASCENDING : Constante pour cr√©er des index tri√©s par ordre croissant

from datetime import datetime
# datetime : Module Python pour manipuler les dates et heures
# Utilis√© ici pour ajouter des timestamps (horodatages) √† nos documents

import logging
# logging : Module pour afficher des messages informatifs pendant l'ex√©cution
# Permet de suivre la progression du script et de d√©boguer en cas d'erreur


# ============================================================================
# CONFIGURATION DU LOGGING : Afficher des messages pendant l'ex√©cution
# ============================================================================

logging.basicConfig(
    level=logging.INFO,  # Niveau INFO : affiche les messages informatifs (pas juste les erreurs)
    format='%(asctime)s - %(levelname)s - %(message)s'
    # Format : [Date/Heure] - [Niveau] - [Message]
    # Exemple : 2026-01-13 19:30:15 - INFO - Connexion r√©ussie!
)
logger = logging.getLogger(__name__)
# Cr√©e un objet "logger" qu'on utilisera pour afficher des messages avec logger.info()


# ============================================================================
# FONCTION PRINCIPALE DE MIGRATION
# ============================================================================

def migrate_data():
    """
    Fonction principale qui orchestre toute la migration.
    
    √âtapes :
    1. Se connecter √† MongoDB
    2. Charger le fichier CSV
    3. Valider les donn√©es
    4. Transformer les donn√©es (dates, structure)
    5. Supprimer les anciennes donn√©es (si on refait la migration)
    6. Ins√©rer les nouvelles donn√©es
    7. Cr√©er des index pour acc√©l√©rer les recherches
    8. V√©rifier que tout s'est bien pass√©
    """
    
    # ========================================================================
    # √âTAPE 1 : CONNEXION √Ä MONGODB
    # ========================================================================
    
    logger.info("üîå Connexion √† MongoDB...")
    
    # MongoClient cr√©e une connexion √† MongoDB
    # "mongodb://localhost:27017/" signifie :
    # - mongodb:// ‚Üí protocole de connexion
    # - localhost ‚Üí serveur local (ton ordinateur)
    # - 27017 ‚Üí port par d√©faut de MongoDB
    client = MongoClient("mongodb://localhost:27017/")
    
    # S√©lection de la base de donn√©es "healthcare_db"
    # Si elle n'existe pas, MongoDB la cr√©era automatiquement
    db = client["healthcare_db"]
    
    # S√©lection de la collection "patients" (√©quivalent d'une "table" en SQL)
    # Si elle n'existe pas, MongoDB la cr√©era automatiquement
    collection = db["patients"]
    
    logger.info("‚úÖ Connexion r√©ussie!")
    
    
    # ========================================================================
    # √âTAPE 2 : CHARGEMENT DU FICHIER CSV
    # ========================================================================
    
    logger.info("üìÇ Chargement du fichier CSV...")
    
    # pandas.read_csv() lit le fichier CSV et le convertit en DataFrame
    # Un DataFrame est comme un tableau Excel en Python
    # Chaque ligne = un patient, chaque colonne = une information (nom, √¢ge, etc.)
    # CORRECTION : "../data/" pour remonter d'un niveau depuis le dossier scripts/
    df = pd.read_csv("../data/healthcare_dataset.csv")
    
    # len(df) compte le nombre de lignes (= nombre de patients)
    logger.info(f"‚úÖ {len(df)} enregistrements charg√©s")
    
    
    # ========================================================================
    # √âTAPE 3 : VALIDATION DES DONN√âES
    # ========================================================================
    
    logger.info("üîç Validation des donn√©es...")
    
    # Affiche la liste des colonnes du CSV pour v√©rifier qu'on a tout
    # Exemple : ['Name', 'Age', 'Gender', 'Blood Type', ...]
    logger.info(f"   Colonnes: {list(df.columns)}")
    
    # Compte le nombre total de valeurs manquantes dans tout le DataFrame
    # df.isnull() ‚Üí identifie les cellules vides
    # .sum().sum() ‚Üí additionne tout
    logger.info(f"   Valeurs manquantes: {df.isnull().sum().sum()}")
    
    # Compte le nombre de lignes en double (patients identiques)
    # df.duplicated() ‚Üí identifie les doublons
    # .sum() ‚Üí compte combien il y en a
    logger.info(f"   Doublons: {df.duplicated().sum()}")
    
    
    # ========================================================================
    # √âTAPE 4 : TRANSFORMATION DES DONN√âES
    # ========================================================================
    
    logger.info("üîÑ Transformation des donn√©es...")
    
    # Conversion des colonnes de dates en objets datetime
    # Par d√©faut, pandas lit les dates comme du texte (string)
    # pd.to_datetime() les convertit en vraies dates manipulables
    df['Date of Admission'] = pd.to_datetime(df['Date of Admission'])
    df['Discharge Date'] = pd.to_datetime(df['Discharge Date'])
    
    # Conversion du DataFrame en liste de dictionnaires
    # 'records' signifie : chaque ligne devient un dictionnaire
    # Exemple : {'Name': 'Bobby Jackson', 'Age': 30, 'Gender': 'Male', ...}
    # C'est le format attendu par MongoDB
    documents = df.to_dict('records')
    
    # Ajout de timestamps (horodatages) √† chaque document
    # created_at : date de cr√©ation du document dans MongoDB
    # updated_at : date de derni√®re modification (m√™me valeur au d√©but)
    # datetime.utcnow() : date/heure actuelle en temps universel (UTC)
    for doc in documents:
        doc['created_at'] = datetime.utcnow()
        doc['updated_at'] = datetime.utcnow()
    
    logger.info(f"‚úÖ {len(documents)} documents pr√™ts")
    
    
    # ========================================================================
    # √âTAPE 5 : SUPPRESSION DES ANCIENNES DONN√âES
    # ========================================================================
    
    # Si on relance le script plusieurs fois, on supprime d'abord les anciennes donn√©es
    # collection.delete_many({}) : supprime tous les documents (le {} vide = "tout")
    # Comme un "TRUNCATE TABLE" en SQL
    collection.delete_many({})
    logger.info("üóëÔ∏è Anciennes donn√©es supprim√©es")
    
    
    # ========================================================================
    # √âTAPE 6 : INSERTION DANS MONGODB
    # ========================================================================
    
    logger.info("üíæ Insertion dans MongoDB...")
    
    # insert_many() ins√®re plusieurs documents en une seule op√©ration
    # C'est beaucoup plus rapide que d'ins√©rer un par un
    # result contient des infos sur l'insertion (IDs g√©n√©r√©s, etc.)
    result = collection.insert_many(documents)
    
    # result.inserted_ids : liste des IDs MongoDB g√©n√©r√©s automatiquement
    # On compte combien il y en a pour v√©rifier que tout est ins√©r√©
    logger.info(f"‚úÖ {len(result.inserted_ids)} documents ins√©r√©s!")
    
    
    # ========================================================================
    # √âTAPE 7 : CR√âATION DES INDEX
    # ========================================================================
    
    logger.info("üìá Cr√©ation des index...")
    
    # Un INDEX acc√©l√®re les recherches sur un champ sp√©cifique
    # C'est comme un sommaire dans un livre : au lieu de lire tout le livre
    # pour trouver un chapitre, on regarde le sommaire
    #
    # ASCENDING : tri croissant (A‚ÜíZ, 0‚Üí9, dates anciennes‚Üír√©centes)
    #
    # On cr√©e des index sur les champs qu'on utilisera souvent pour filtrer :
    
    collection.create_index([("Name", ASCENDING)])
    # Acc√©l√®re : db.patients.find({"Name": "Bobby Jackson"})
    
    collection.create_index([("Medical Condition", ASCENDING)])
    # Acc√©l√®re : db.patients.find({"Medical Condition": "Diabetes"})
    
    collection.create_index([("Hospital", ASCENDING)])
    # Acc√©l√®re : db.patients.find({"Hospital": "Smith PLC"})
    
    collection.create_index([("Date of Admission", ASCENDING)])
    # Acc√©l√®re : db.patients.find({"Date of Admission": {$gte: date}})
    
    logger.info("‚úÖ Index cr√©√©s!")
    
    
    # ========================================================================
    # √âTAPE 8 : V√âRIFICATION FINALE
    # ========================================================================
    
    logger.info("‚úîÔ∏è V√©rification finale...")
    
    # Compte le nombre total de documents dans la collection
    # Doit correspondre au nombre de lignes du CSV
    count = collection.count_documents({})
    logger.info(f"‚úÖ Total dans MongoDB: {count} documents")
    
    # R√©cup√®re UN document au hasard pour l'afficher en exemple
    # find_one() sans filtre retourne le premier document trouv√©
    sample = collection.find_one()
    logger.info(f"üìÑ Exemple de document: {sample['Name']}, {sample['Age']} ans")
    
    # Fermeture de la connexion MongoDB
    # Bonne pratique : toujours fermer les connexions pour lib√©rer les ressources
    client.close()
    
    logger.info("üéâ MIGRATION TERMIN√âE AVEC SUCC√àS!")


# ============================================================================
# POINT D'ENTR√âE DU SCRIPT
# ============================================================================

if __name__ == "__main__":
    # Cette ligne signifie : "Si on ex√©cute CE fichier directement"
    # (pas si on l'import dans un autre fichier)
    # Alors on lance la fonction migrate_data()
    migrate_data()
